[input]


[network]
inputDim = 1
outputDim = 1
neuronsPerLayer = 100,100,100
activationPerLayer = relu
recurrentActivation = None
initWeights = uniform
dropout = 0.2
optimiser = adam
learningRate = 0.001
loss = mse
epochs = 10
batchSize = 16 

[tuning]


[output]
