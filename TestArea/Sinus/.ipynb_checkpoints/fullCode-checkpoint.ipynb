{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "import numpy as np\n",
    "from numpy import newaxis\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(filename, seq_len, normalise_window):\n",
    "    f = open(filename, 'rb').read()\n",
    "    data = f.decode().split('\\n')\n",
    "\n",
    "    sequence_length = seq_len + 1\n",
    "    result = []\n",
    "    for index in range(len(data) - sequence_length):\n",
    "        result.append(data[index: index + sequence_length])\n",
    "\n",
    "    result = np.array(result)\n",
    "\n",
    "    row = round(0.9 * result.shape[0])\n",
    "    train = result[:int(row), :]\n",
    "    np.random.shuffle(train)\n",
    "    x_train = train[:, :-1]\n",
    "    y_train = train[:, -1]\n",
    "    x_test = result[int(row):, :-1]\n",
    "    y_test = result[int(row):, -1]\n",
    "\n",
    "    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
    "    x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))  \n",
    "\n",
    "    return [x_train, y_train, x_test, y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model(layers):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(LSTM(\n",
    "        input_dim=layers[0],\n",
    "        output_dim=layers[1],\n",
    "        return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(LSTM(\n",
    "        layers[2],\n",
    "        return_sequences=False))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(\n",
    "        output_dim=layers[3]))\n",
    "    model.add(Activation(\"linear\"))\n",
    "\n",
    "    start = time.time()\n",
    "    model.compile(loss=\"mse\", optimizer=\"rmsprop\")\n",
    "    print(\"> Compilation Time : \", time.time() - start)\n",
    "    return model\n",
    "\n",
    "def predict_point_by_point(model, data):\n",
    "    #Predict each timestep given the last sequence of true data, in effect only predicting 1 step ahead each time\n",
    "    predicted = model.predict(data)\n",
    "    predicted = np.reshape(predicted, (predicted.size,))\n",
    "    return predicted\n",
    "\n",
    "def predict_sequence_full(model, data, window_size):\n",
    "    #Shift the window by 1 new prediction each time, re-run predictions on new window\n",
    "    curr_frame = data[0]\n",
    "    predicted = []\n",
    "    for i in range(len(data)):\n",
    "        predicted.append(model.predict(curr_frame[newaxis,:,:])[0,0])\n",
    "        curr_frame = curr_frame[1:]\n",
    "        curr_frame = np.insert(curr_frame, [window_size-1], predicted[-1], axis=0)\n",
    "    return predicted\n",
    "\n",
    "def predict_sequences_multiple(model, data, window_size, prediction_len):\n",
    "    #Predict sequence of 50 steps before shifting prediction run forward by 50 steps\n",
    "    prediction_seqs = []\n",
    "    for i in range(int(len(data)/prediction_len)):\n",
    "        curr_frame = data[i*prediction_len]\n",
    "        predicted = []\n",
    "        for j in range(prediction_len):\n",
    "            predicted.append(model.predict(curr_frame[newaxis,:,:])[0,0])\n",
    "            curr_frame = curr_frame[1:]\n",
    "            curr_frame = np.insert(curr_frame, [window_size-1], predicted[-1], axis=0)\n",
    "        prediction_seqs.append(predicted)\n",
    "    return prediction_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Loading data... \n",
      "> Data Loaded. Compiling...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kowalski/Software/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:7: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "/home/kowalski/Software/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:7: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(units=50, return_sequences=True, input_shape=(None, 1))`\n",
      "/home/kowalski/Software/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:16: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=1)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('> Compilation Time : ', 0.018739938735961914)\n",
      "Train on 4232 samples, validate on 223 samples\n",
      "Epoch 1/1\n",
      "4232/4232 [==============================] - 24s - loss: 0.2099 - val_loss: 0.1037\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n"
     ]
    }
   ],
   "source": [
    "def plot_results(predicted_data, true_data):\n",
    "    fig = plt.figure(facecolor='white')\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.plot(true_data, label='True Data')\n",
    "    plt.plot(predicted_data, label='Prediction')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def plot_results_multiple(predicted_data, true_data, prediction_len):\n",
    "    fig = plt.figure(facecolor='white')\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.plot(true_data, label='True Data')\n",
    "    #Pad the list of predictions to shift it in the graph to it's correct start\n",
    "    for i, data in enumerate(predicted_data):\n",
    "        padding = [None for p in range(i * prediction_len)]\n",
    "        plt.plot(padding + data, label='Prediction')\n",
    "        plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "epochs  = 1\n",
    "seq_len = 50\n",
    "\n",
    "print('> Loading data... ')\n",
    "\n",
    "#X_train, y_train, X_test, y_test = lstm.load_data('sp500.csv', seq_len, True)\n",
    "X_train, y_train, X_test, y_test = load_data('sp500.csv', seq_len, True)\n",
    "\n",
    "print('> Data Loaded. Compiling...')\n",
    "\n",
    "#model = lstm.build_model([1, 50, 100, 1])\n",
    "model = build_model([1, 50, 100, 1])\n",
    "\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=512,\n",
    "    nb_epoch=epochs,\n",
    "    validation_split=0.05)\n",
    "\n",
    "#predicted = lstm.predict_point_by_point(model, X_test)\n",
    "predicted = predict_point_by_point(model, X_test)\n",
    "\n",
    "plot_results_multiple(predictions, y_test, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.20214868  1.24535871  1.28412163  1.318277    1.34768069  1.37220502\n",
      "  1.39173687  1.40617919  1.41544843  1.41947532  1.41820168  1.41158164\n",
      "  1.39957988  1.38217223  1.35934556  1.33109963  1.29744923  1.25842619\n",
      "  1.21408319  1.16449857  1.10978055  1.05007195  0.98555624  0.91646141\n",
      "  0.8430652   0.76569724  0.68474072  0.60063231  0.51385903  0.42495316\n",
      "  0.33448473  0.24305165  0.1512675   0.05974866 -0.03089994 -0.12009829\n",
      " -0.207304   -0.29202372 -0.37382102 -0.45232266 -0.52722085 -0.59827292\n",
      " -0.66529787 -0.72817183 -0.78681993 -0.84120929 -0.89133996 -0.93723714\n",
      " -0.97894269 -1.01650918 -1.04999268 -1.07944894 -1.10492873 -1.12647557\n",
      " -1.14412332 -1.15789557 -1.16780519 -1.17385375 -1.17603326 -1.17432785\n",
      " -1.16871309 -1.15916014 -1.14563632 -1.12810874 -1.10654569 -1.08091986\n",
      " -1.05121148 -1.01741135 -0.9795233  -0.93756843 -0.89158756 -0.84164476\n",
      " -0.78783011 -0.73026252 -0.6690914  -0.60449862 -0.53669959 -0.46594185\n",
      " -0.39250505 -0.31669784 -0.23885451 -0.15933052 -0.07849661  0.00326645\n",
      "  0.08557457  0.16804551  0.2503044   0.33198759  0.41274545  0.49224383\n",
      "  0.57016492  0.64620608  0.72007895  0.7915082   0.86022937  0.92598885\n",
      "  0.9885422   1.04765427  1.10310054  1.15466595  1.20214868  1.24535871\n",
      "  1.28412163  1.318277    1.34768069  1.37220502  1.39173687  1.40617919\n",
      "  1.41544843  1.41947532  1.41820168  1.41158164  1.39957988  1.38217223\n",
      "  1.35934556  1.33109963  1.29744923  1.25842619  1.21408319  1.16449857\n",
      "  1.10978055  1.05007195  0.98555624  0.91646141  0.8430652   0.76569724\n",
      "  0.68474072  0.60063231  0.51385903  0.42495316  0.33448473  0.24305165\n",
      "  0.1512675   0.05974866 -0.03089994 -0.12009829 -0.207304   -0.29202372\n",
      " -0.37382102 -0.45232266 -0.52722085 -0.59827292 -0.66529787 -0.72817183\n",
      " -0.78681993 -0.84120929 -0.89133996 -0.93723714 -0.97894269 -1.01650918\n",
      " -1.04999268 -1.07944894 -1.10492873 -1.12647557 -1.14412332 -1.15789557\n",
      " -1.16780519 -1.17385375 -1.17603326 -1.17432785 -1.16871309 -1.15916014\n",
      " -1.14563632 -1.12810874 -1.10654569 -1.08091986 -1.05121148 -1.01741135\n",
      " -0.9795233  -0.93756843 -0.89158756 -0.84164476 -0.78783011 -0.73026252\n",
      " -0.6690914  -0.60449862 -0.53669959 -0.46594185 -0.39250505 -0.31669784\n",
      " -0.23885451 -0.15933052 -0.07849661  0.00326645  0.08557457  0.16804551\n",
      "  0.2503044   0.33198759  0.41274545  0.49224383  0.57016492  0.64620608\n",
      "  0.72007895  0.7915082   0.86022937  0.92598885  0.9885422   1.04765427\n",
      "  1.10310054  1.15466595  1.20214868  1.24535871  1.28412163  1.318277\n",
      "  1.34768069  1.37220502  1.39173687  1.40617919  1.41544843  1.41947532\n",
      "  1.41820168  1.41158164  1.39957988  1.38217223  1.35934556  1.33109963\n",
      "  1.29744923  1.25842619  1.21408319  1.16449857  1.10978055  1.05007195\n",
      "  0.98555624  0.91646141  0.8430652   0.76569724  0.68474072  0.60063231\n",
      "  0.51385903  0.42495316  0.33448473  0.24305165  0.1512675   0.05974866\n",
      " -0.03089994 -0.12009829 -0.207304   -0.29202372 -0.37382102 -0.45232266\n",
      " -0.52722085 -0.59827292 -0.66529787 -0.72817183 -0.78681993 -0.84120929\n",
      " -0.89133996 -0.93723714 -0.97894269 -1.01650918 -1.04999268 -1.07944894\n",
      " -1.10492873 -1.12647557 -1.14412332 -1.15789557 -1.16780519 -1.17385375\n",
      " -1.17603326 -1.17432785 -1.16871309 -1.15916014 -1.14563632 -1.12810874\n",
      " -1.10654569 -1.08091986 -1.05121148 -1.01741135 -0.9795233  -0.93756843\n",
      " -0.89158756 -0.84164476 -0.78783011 -0.73026252 -0.6690914  -0.60449862\n",
      " -0.53669959 -0.46594185 -0.39250505 -0.31669784 -0.23885451 -0.15933052\n",
      " -0.07849661  0.00326645  0.08557457  0.16804551  0.2503044   0.33198759\n",
      "  0.41274545  0.49224383  0.57016492  0.64620608  0.72007895  0.7915082\n",
      "  0.86022937  0.92598885  0.9885422   1.04765427  1.10310054  1.15466595\n",
      "  1.20214868  1.24535871  1.28412163  1.318277    1.34768069  1.37220502\n",
      "  1.39173687  1.40617919  1.41544843  1.41947532  1.41820168  1.41158164\n",
      "  1.39957988  1.38217223  1.35934556  1.33109963  1.29744923  1.25842619\n",
      "  1.21408319  1.16449857  1.10978055  1.05007195  0.98555624  0.91646141\n",
      "  0.8430652   0.76569724  0.68474072  0.60063231  0.51385903  0.42495316\n",
      "  0.33448473  0.24305165  0.1512675   0.05974866 -0.03089994 -0.12009829\n",
      " -0.207304   -0.29202372 -0.37382102 -0.45232266 -0.52722085 -0.59827292\n",
      " -0.66529787 -0.72817183 -0.78681993 -0.84120929 -0.89133996 -0.93723714\n",
      " -0.97894269 -1.01650918 -1.04999268 -1.07944894 -1.10492873 -1.12647557\n",
      " -1.14412332 -1.15789557 -1.16780519 -1.17385375 -1.17603326 -1.17432785\n",
      " -1.16871309 -1.15916014 -1.14563632 -1.12810874 -1.10654569 -1.08091986\n",
      " -1.05121148 -1.01741135 -0.9795233  -0.93756843 -0.89158756 -0.84164476\n",
      " -0.78783011 -0.73026252 -0.6690914  -0.60449862 -0.53669959 -0.46594185\n",
      " -0.39250505 -0.31669784 -0.23885451 -0.15933052 -0.07849661  0.00326645\n",
      "  0.08557457  0.16804551  0.2503044   0.33198759  0.41274545  0.49224383\n",
      "  0.57016492  0.64620608  0.72007895  0.7915082   0.86022937  0.92598885\n",
      "  0.9885422   1.04765427  1.10310054  1.15466595  1.20214868  1.24535871\n",
      "  1.28412163  1.318277    1.34768069  1.37220502  1.39173687  1.40617919\n",
      "  1.41544843  1.41947532  1.41820168  1.41158164  1.39957988  1.38217223\n",
      "  1.35934556  1.33109963  1.29744923  1.25842619  1.21408319  1.16449857\n",
      "  1.10978055  1.05007195  0.98555624  0.91646141  0.8430652   0.76569724\n",
      "  0.68474072  0.60063231  0.51385903  0.42495316  0.33448473  0.24305165\n",
      "  0.1512675   0.05974866 -0.03089994 -0.12009829 -0.207304   -0.29202372\n",
      " -0.37382102 -0.45232266 -0.52722085 -0.59827292 -0.66529787 -0.72817183\n",
      " -0.78681993 -0.84120929 -0.89133996 -0.93723714 -0.97894269 -1.01650918\n",
      " -1.04999268 -1.07944894 -1.10492873 -1.12647557 -1.14412332 -1.15789557\n",
      " -1.16780519 -1.17385375 -1.17603326 -1.17432785 -1.16871309 -1.15916014\n",
      " -1.14563632 -1.12810874 -1.10654569 -1.08091986 -1.05121148 -1.01741135\n",
      " -0.9795233  -0.93756843 -0.89158756 -0.84164476 -0.78783011 -0.73026252\n",
      " -0.6690914  -0.60449862 -0.53669959 -0.46594185 -0.39250505 -0.31669784\n",
      " -0.23885451 -0.15933052 -0.07849661  0.00326645  0.08557457  0.16804551\n",
      "  0.2503044   0.33198759  0.41274545  0.49224383  0.57016492  0.64620608\n",
      "  0.72007895  0.79150814  0.86022931]\n"
     ]
    }
   ],
   "source": [
    "print predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
